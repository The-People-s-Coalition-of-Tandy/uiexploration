<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Visualizer</title>
    <style>
        body { margin: 0; overflow: hidden; }
        #audio-controls {
            position: fixed;
            top: 20px;
            left: 20px;
            z-index: 100;
            background: rgba(0,0,0,0.7);
            padding: 10px;
            border-radius: 5px;
            color: white;
        }
    </style>
</head>
<body>
    <div id="audio-controls">
        <input type="file" id="audio-input" accept="audio/*">
        <button id="play-btn">Play</button>
        <button id="pause-btn">Pause</button>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        // Audio context and analyzer setup
        let audioContext, analyzer, audioSource;
        const fftSize = 256;
        let dataArray;

        // Initialize audio
        async function initAudio() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyzer = audioContext.createAnalyser();
            analyzer.fftSize = fftSize;
            dataArray = new Uint8Array(analyzer.frequencyBinCount);
        }

        // Setup audio file handling
        document.getElementById('audio-input').addEventListener('change', async (e) => {
            const file = e.target.files[0];
            const arrayBuffer = await file.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            if (audioSource) {
                audioSource.disconnect();
            }
            
            audioSource = audioContext.createBufferSource();
            audioSource.buffer = audioBuffer;
            audioSource.connect(analyzer);
            analyzer.connect(audioContext.destination);
        });

        document.getElementById('play-btn').addEventListener('click', () => {
            if (audioSource) {
                audioContext.resume();
                audioSource.start(0);
            }
        });

        document.getElementById('pause-btn').addEventListener('click', () => {
            if (audioContext) {
                audioContext.suspend();
            }
        });

        // Three.js setup
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setClearColor(0x000000, 0);
        document.body.appendChild(renderer.domElement);

        // Create plane with higher segment count for more detailed waves
        const geometry = new THREE.PlaneGeometry(5, 4, 200, 200);
        const material = new THREE.MeshPhongMaterial({
            color: 0x801080,
            specular: 0x444444,
            shininess: 30,
            flatShading: false,
            side: THREE.DoubleSide
        });

        const plane = new THREE.Mesh(geometry, material);
        scene.add(plane);

        // Enhanced lighting
        const light = new THREE.DirectionalLight(0xffffff, 0.8);
        light.position.set(-5, 5, 7);
        scene.add(light);
        const light2 = new THREE.DirectionalLight(0xffffff, 0.5);
        light2.position.set(5, -5, 7);
        scene.add(light2);
        const ambientLight = new THREE.AmbientLight(0x404040);
        scene.add(ambientLight);

        camera.position.z = 2;

        // Physics variables
        const originalPositions = geometry.attributes.position.array.slice();
        const velocities = new Float32Array(geometry.attributes.position.array.length);
        const forces = new Float32Array(geometry.attributes.position.array.length);
        const SPRING_CONSTANT = 0.1;
        const DAMPING = 0.97;
        const MASS = 20.90;
        const AUDIO_MULTIPLIER = 0.02;

        // Normal calculation
        function computeCustomNormals() {
            const positions = geometry.attributes.position.array;
            const normals = geometry.attributes.normal.array;
            const indices = geometry.index.array;
            
            normals.fill(0);
            
            for (let i = 0; i < indices.length; i += 3) {
                const idx1 = indices[i] * 3;
                const idx2 = indices[i + 1] * 3;
                const idx3 = indices[i + 2] * 3;
                
                const v1 = new THREE.Vector3(positions[idx1], positions[idx1 + 1], positions[idx1 + 2]);
                const v2 = new THREE.Vector3(positions[idx2], positions[idx2 + 1], positions[idx2 + 2]);
                const v3 = new THREE.Vector3(positions[idx3], positions[idx3 + 1], positions[idx3 + 2]);
                
                const edge1 = v2.sub(v1);
                const edge2 = v3.sub(v1);
                const normal = edge1.cross(edge2).normalize();
                
                for (let j = 0; j < 3; j++) {
                    const idx = indices[i + j] * 3;
                    normals[idx] += normal.x;
                    normals[idx + 1] += normal.y;
                    normals[idx + 2] += normal.z;
                }
            }
            
            for (let i = 0; i < normals.length; i += 3) {
                const length = Math.sqrt(
                    normals[i] * normals[i] + 
                    normals[i + 1] * normals[i + 1] + 
                    normals[i + 2] * normals[i + 2]
                );
                
                if (length > 0) {
                    normals[i] /= length;
                    normals[i + 1] /= length;
                    normals[i + 2] /= length;
                }
            }
            
            geometry.attributes.normal.needsUpdate = true;
        }

        function updatePhysics() {
            if (!analyzer) return;
            
            const positions = geometry.attributes.position.array;
            forces.fill(0);
            
            // Get audio data
            analyzer.getByteFrequencyData(dataArray);
            
            // Create ripples based on audio frequencies
            for (let i = 0; i < positions.length; i += 3) {
                const x = positions[i];
                const y = positions[i + 1];
                
                // Map vertex position to frequency array index
                const freqIndex = Math.floor(Math.abs(x * y * 10) % analyzer.frequencyBinCount);
                const audioValue = dataArray[freqIndex];
                
                // Apply force based on audio data
                forces[i + 2] += (audioValue / 255) * AUDIO_MULTIPLIER;
                
                // Spring forces for restoration
                const dx = originalPositions[i] - positions[i];
                const dy = originalPositions[i + 1] - positions[i + 1];
                const dz = originalPositions[i + 2] - positions[i + 2];
                
                forces[i] += dx * SPRING_CONSTANT;
                forces[i + 1] += dy * SPRING_CONSTANT;
                forces[i + 2] += dz * SPRING_CONSTANT;
                
                velocities[i] = velocities[i] * DAMPING + forces[i] / MASS;
                velocities[i + 1] = velocities[i + 1] * DAMPING + forces[i + 1] / MASS;
                velocities[i + 2] = velocities[i + 2] * DAMPING + forces[i + 2] / MASS;
                
                positions[i] += velocities[i];
                positions[i + 1] += velocities[i + 1];
                positions[i + 2] += velocities[i + 2];
            }

            geometry.attributes.position.needsUpdate = true;
            computeCustomNormals();
        }

        function animate() {
            requestAnimationFrame(animate);
            updatePhysics();
            renderer.render(scene, camera);
        }

        function onWindowResize() {
            const aspect = window.innerWidth / window.innerHeight;
            camera.aspect = aspect;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            
            const distance = camera.position.z;
            const vFov = camera.fov * Math.PI / 180;
            const height = 2 * Math.tan(vFov / 2) * distance;
            const width = height * aspect;
            
            plane.scale.set(width / 4 * 1.2, height / 3 * 1.2, 1);
        }

        window.addEventListener('resize', onWindowResize);
        onWindowResize();
        initAudio();
        animate();
    </script>
</body>
</html>